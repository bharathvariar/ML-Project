{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d3c9c5c",
   "metadata": {},
   "source": [
    "# Fisher's Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354b96a2",
   "metadata": {},
   "source": [
    "## Importing Libraries and Data Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64fd3eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from feature_engineering import *\n",
    "warnings.filterwarnings('ignore')\n",
    "PI = np.pi\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f91dbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume X_train and y_train are the training data and labels respectively\n",
    "df = pd.read_csv(\"../data/dataset1.csv\")\n",
    "df.head(-1)\n",
    "df=df.drop('id',axis=1)\n",
    "mean = np.mean(df, axis=0)\n",
    "for i in range(1, df.shape[1]):\n",
    "    df.iloc[:, i].fillna(mean[i-1], inplace=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9758d2",
   "metadata": {},
   "source": [
    "## Task 1: FLDM on raw data (FLDM1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8faf76e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the FLDM model\n",
    "fldm1 = LinearDiscriminantAnalysis(n_components=1)\n",
    "fldm1.fit(X_train, y_train)\n",
    "\n",
    "# project the training data onto the 1-dimensional FLDM space\n",
    "X_train_lda = fldm1.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c98b567d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: {'true_positive': 41, 'true_negative': 142, 'false_positive': 3, 'false_negative': 2}\n",
      "Accuracy: 97.34042553191489%\n",
      "Precision: 93.18181818181819%\n",
      "Recall: 95.34883720930233%\n"
     ]
    }
   ],
   "source": [
    "# find the decision boundary in the 1-dimensional FLDM space\n",
    "mean_pos = np.mean(X_train_lda[y_train == 1])\n",
    "mean_neg = np.mean(X_train_lda[y_train == -1])\n",
    "std_pos = np.std(X_train_lda[y_train == 1])\n",
    "std_neg = np.std(X_train_lda[y_train == -1])\n",
    "\n",
    "threshold = (mean_pos + mean_neg) / 2\n",
    "\n",
    "# project the testing data onto the 1-dimensional FLDM space\n",
    "X_test_lda = fldm1.transform(X_test)\n",
    "\n",
    "# evaluate the performance of the model on the testing data\n",
    "y_pred = np.where(X_test_lda > threshold, 1, -1)\n",
    "accuracy_fldm1 = evaluate(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e75d9a6",
   "metadata": {},
   "source": [
    "## Task 2: FLDM on data with shuffled columns (FLDM2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10829f22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>compactness_se</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>concave points_se</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>perimeter_se</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>symmetry_se</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>radius_se</th>\n",
       "      <th>smoothness_se</th>\n",
       "      <th>fractal_dimension_se</th>\n",
       "      <th>concavity_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.04904</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.01587</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>8.589</td>\n",
       "      <td>17.99</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.03003</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>25.38</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>1.0950</td>\n",
       "      <td>0.006399</td>\n",
       "      <td>0.006193</td>\n",
       "      <td>0.3001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.01308</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.01340</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>3.398</td>\n",
       "      <td>20.57</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.01389</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>24.99</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.5435</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>0.0869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.04006</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.02058</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>4.585</td>\n",
       "      <td>19.69</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.02250</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>23.57</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.7456</td>\n",
       "      <td>0.006150</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>0.1974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.07458</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.01867</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>3.445</td>\n",
       "      <td>11.42</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.05963</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>14.91</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.4956</td>\n",
       "      <td>0.009110</td>\n",
       "      <td>0.009208</td>\n",
       "      <td>0.2414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.02461</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.01885</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>5.438</td>\n",
       "      <td>20.29</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.01756</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>22.54</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.7572</td>\n",
       "      <td>0.011490</td>\n",
       "      <td>0.005115</td>\n",
       "      <td>0.1980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   concave points_worst  compactness_se  area_worst  concave points_se  \\\n",
       "0                0.2654         0.04904      2019.0            0.01587   \n",
       "1                0.1860         0.01308      1956.0            0.01340   \n",
       "2                0.2430         0.04006      1709.0            0.02058   \n",
       "3                0.2575         0.07458       567.7            0.01867   \n",
       "4                0.1625         0.02461      1575.0            0.01885   \n",
       "\n",
       "   symmetry_mean  fractal_dimension_mean  symmetry_worst  smoothness_worst  \\\n",
       "0         0.2419                 0.07871          0.4601            0.1622   \n",
       "1         0.1812                 0.05667          0.2750            0.1238   \n",
       "2         0.2069                 0.05999          0.3613            0.1444   \n",
       "3         0.2597                 0.09744          0.6638            0.2098   \n",
       "4         0.1809                 0.05883          0.2364            0.1374   \n",
       "\n",
       "   perimeter_se  radius_mean  ...  texture_worst  concavity_worst  \\\n",
       "0         8.589        17.99  ...          17.33           0.7119   \n",
       "1         3.398        20.57  ...          23.41           0.2416   \n",
       "2         4.585        19.69  ...          25.53           0.4504   \n",
       "3         3.445        11.42  ...          26.50           0.6869   \n",
       "4         5.438        20.29  ...          16.67           0.4000   \n",
       "\n",
       "   symmetry_se  fractal_dimension_worst  radius_worst  concave points_mean  \\\n",
       "0      0.03003                  0.11890         25.38              0.14710   \n",
       "1      0.01389                  0.08902         24.99              0.07017   \n",
       "2      0.02250                  0.08758         23.57              0.12790   \n",
       "3      0.05963                  0.17300         14.91              0.10520   \n",
       "4      0.01756                  0.07678         22.54              0.10430   \n",
       "\n",
       "   radius_se  smoothness_se  fractal_dimension_se  concavity_mean  \n",
       "0     1.0950       0.006399              0.006193          0.3001  \n",
       "1     0.5435       0.005225              0.003532          0.0869  \n",
       "2     0.7456       0.006150              0.004571          0.1974  \n",
       "3     0.4956       0.009110              0.009208          0.2414  \n",
       "4     0.7572       0.011490              0.005115          0.1980  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# randomly shuffle the order of features in the training data\n",
    "np.random.seed(42)\n",
    "n_features = X_train.shape[1]\n",
    "feature_order = np.random.permutation(n_features)\n",
    "X_train_shuffled = X_train[X_train.columns[feature_order]]\n",
    "X_train_shuffled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdd866f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the FLDM model\n",
    "fldm2 = LinearDiscriminantAnalysis(n_components=1)\n",
    "fldm2.fit(X_train_shuffled, y_train)\n",
    "\n",
    "# project the training data onto the 1-dimensional FLDM space\n",
    "X_train_lda = fldm2.transform(X_train_shuffled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb5c3afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: {'true_positive': 41, 'true_negative': 142, 'false_positive': 3, 'false_negative': 2}\n",
      "Accuracy: 97.34042553191489%\n",
      "Precision: 93.18181818181819%\n",
      "Recall: 95.34883720930233%\n"
     ]
    }
   ],
   "source": [
    "# find the decision boundary in the 1-dimensional FLDM space\n",
    "mean_pos = np.mean(X_train_lda[y_train == 1])\n",
    "mean_neg = np.mean(X_train_lda[y_train == -1])\n",
    "std_pos = np.std(X_train_lda[y_train == 1])\n",
    "std_neg = np.std(X_train_lda[y_train == -1])\n",
    "\n",
    "threshold = (mean_pos + mean_neg) / 2\n",
    "\n",
    "# shuffle the order of features in the testing data\n",
    "X_test_shuffled = X_test[X_test.columns[feature_order]]\n",
    "\n",
    "# project the testing data onto the 1-dimensional FLDM space\n",
    "X_test_lda = fldm2.transform(X_test_shuffled)\n",
    "\n",
    "# evaluate the performance of the model on the testing data\n",
    "y_pred = np.where(X_test_lda > threshold, 1, -1)\n",
    "accuracy2 = evaluate(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
